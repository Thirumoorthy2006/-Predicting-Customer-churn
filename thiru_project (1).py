# -*- coding: utf-8 -*-
"""Thiru Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ofqVvj4YQiMy3KP7n_3aNhLlJ8XYe0Bb
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import joblib

# Step 1 & 2: Define the Problem & Load the Data
print("\nðŸ”¹ Loading dataset...")
df = pd.read_csv("customer_churn_dataset.csv")
print("Dataset loaded successfully!\n")
print("First 5 rows of the dataset:")
print(df.head())
print("\nDataset Info:")
print(df.info())

# Step 3: Data Preprocessing
print("\nðŸ”¹ Encoding categorical features...")
label_encoders = {}
categorical_cols = ['Gender', 'Geography']
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

print("Encoding complete.")

# Feature and target split
X = df.drop(["CustomerID", "Churn"], axis=1)
y = df["Churn"]

# Scale numerical features
print("\nðŸ”¹ Scaling features...")
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
print("\nðŸ”¹ Splitting dataset into train and test sets...")
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
print("Train shape:", X_train.shape)
print("Test shape:", X_test.shape)

# Step 4: Exploratory Data Analysis (EDA)
print("\nðŸ”¹ Plotting churn distribution...")
sns.countplot(x='Churn', data=df)
plt.title("Churn Distribution")
plt.savefig("churn_distribution.png")
plt.show()

print("\nðŸ”¹ Plotting correlation heatmap...")
plt.figure(figsize=(10, 8))
numeric_df = df.select_dtypes(include=[np.number])  # Select only numeric columns
sns.heatmap(numeric_df.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Feature Correlation Heatmap")
plt.savefig("correlation_heatmap.png")
plt.show()

# Step 5: Feature Engineering (Optional)
# Not necessary here, skipping for simplicity

# Step 6: Model Selection
print("\nðŸ”¹ Training models...")
# Logistic Regression
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

# Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

def evaluate_model(model, name):
    y_pred = model.predict(X_test)
    print(f"\nðŸ“Š {name} Evaluation Report")
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("ROC-AUC Score:", roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))

evaluate_model(lr_model, "Logistic Regression")
evaluate_model(rf_model, "Random Forest")

print("\nðŸ”¹ Plotting feature importances from Random Forest...")
importances = rf_model.feature_importances_
feature_names = X.columns
feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)

plt.figure(figsize=(10,6))
feat_imp.plot(kind='bar')
plt.title('Feature Importance - Random Forest')
plt.savefig("feature_importance.png")
plt.show()

print("\nðŸ’¾ Saving the model and scaler...")
joblib.dump(rf_model, "rf_churn_model.pkl")
joblib.dump(scaler, "scaler.pkl")
print("Model and scaler saved successfully.")

print("\nâœ… Project pipeline complete.")